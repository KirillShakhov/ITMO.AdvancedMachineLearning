{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9QLe_T6GZUd"
   },
   "source": [
    "# Задание на программирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYlIf2yHv8hz"
   },
   "source": [
    "**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDQzNIZXAoFE"
   },
   "source": [
    "Зададим гиперпараметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "NOMw2ZbOAmOZ",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:49.741944Z",
     "start_time": "2023-10-13T21:37:49.714331Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
    "gamma = 0.9 # Коэффциент дисконтирования гамма\n",
    "random_seed = 6 #Random seed\n",
    "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
    "lr_rate = 0.9 #Коэффициент скорости обучения альфа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQu5IYHX8jId"
   },
   "source": [
    "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "M2G81i4_lOQE",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:50.526325Z",
     "start_time": "2023-10-13T21:37:49.724046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: could not create work tree dir 'gym_0_18_0': No such file or directory\r\n",
      "[Errno 2] No such file or directory: 'gym_0_18_0'\n",
      "/Users/kirill/PycharmProjects/advanced-ml-python-deep-learning/exercise9/gym_0_18_0/gym_0_18_0/gym_0_18_0\n",
      "The folder you are executing pip from can no longer be found.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/pip/__main__.py\", line 8, in <module>\r\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/pip/__main__.py\", line 8, in <module>\r\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Установим нужную версию библиотеки gym\n",
    "!git clone https://github.com/dvolchek/gym_0_18_0.git -q\n",
    "%cd gym_0_18_0\n",
    "!pip install -e. -q\n",
    "%pip install scipy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "awL7CCCwD6C3",
    "outputId": "5b2d42db-dc19-4cef-f753-805b8b6be9c3",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:50.537656Z",
     "start_time": "2023-10-13T21:37:50.534243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваша карта\n",
      "\n",
      "\u001B[41mS\u001B[0mFHFFF\n",
      "FFFFFF\n",
      "FFFHHF\n",
      "HHFFHF\n",
      "FFFHFF\n",
      "FHFFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def generate_random_map(size, p, sd):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "    np.random.seed(sd)\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0,0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r,c) in discovered:\n",
    "                discovered.add((r,c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if (res[r_new][c_new] not in '#H'):\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "#Генерация карты\n",
    "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
    "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
    "print(\"Ваша карта\")\n",
    "env.render() #Выводим карту на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDCexoEU9a_c"
   },
   "source": [
    "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
    "\n",
    "`action = env.action_space.sample()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5TbDqn6G_Pt"
   },
   "source": [
    "# Задача 1\n",
    "Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "CdQBpxaTOK7u",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:50.541096Z",
     "start_time": "2023-10-13T21:37:50.539196Z"
    }
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    action=0\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, done):\n",
    "    # Вычисляем максимальное значение Q для нового состояния state2\n",
    "    # max_q = np.max(Q[state2, :])\n",
    "    \n",
    "    # Обновляем значение Q-функции для текущей пары состояние-действие\n",
    "    # Q[state, action] = (1 - lr_rate) * Q[state, action] + lr_rate * (reward + gamma * max_q)\n",
    "    Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2,:]) - Q[state, action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7COGeyA_Ist3"
   },
   "source": [
    "# Задача 2\n",
    "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0adDl7NvJoQP"
   },
   "source": [
    "Поясним, что возвращает функция ```env.step(action)```\n",
    "\n",
    "```state2``` -- следующее состояние\n",
    "\n",
    "```reward``` -- награда\n",
    "\n",
    "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aq92-dWiOchF",
    "outputId": "91ec4dc4-fb39-4818-ac78-79c9fe6d0ee7",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:52.613940Z",
     "start_time": "2023-10-13T21:37:50.544799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4841.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Inititalization\n",
    "np.random.seed(random_seed)\n",
    "total_games = 10000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "wins_in_a_row = 0\n",
    "total_wins = 0\n",
    "game_of_fifth_win = None\n",
    "\n",
    "# Main cycle\n",
    "for game in tqdm(range(total_games)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "        t += 1\n",
    "        action = choose_action(state)\n",
    "        state2, reward, done, info = env.step(action)\n",
    "        if t == max_steps:\n",
    "            done = True\n",
    "        learn(state, state2, reward, action, done)\n",
    "        state = state2\n",
    "        if done:\n",
    "            if reward > 0:  # if it's a win\n",
    "                total_wins += 1\n",
    "                wins_in_a_row += 1\n",
    "                if wins_in_a_row == 5 and game_of_fifth_win is None:\n",
    "                    game_of_fifth_win = game + 1\n",
    "            else:\n",
    "                wins_in_a_row = 0  # reset the wins in a row counter if the agent didn't win\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFuxsqdRLOS9"
   },
   "source": [
    "Вывод ответов при заданных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "xZbJtFnhLa7w",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:37:52.616555Z",
     "start_time": "2023-10-13T21:37:52.614204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество побед в серии из 10 000 игр:  2526\n",
      "Пять побед подряд впервые было одержано в игре  7309\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество побед в серии из 10 000 игр: \", total_wins)\n",
    "print(\"Пять побед подряд впервые было одержано в игре \", game_of_fifth_win)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSXdSiG2WI71"
   },
   "source": [
    "Должны получиться следующие результаты.\n",
    "\n",
    "\n",
    "*  Количество побед в серии из 10 000 игр:  7914\n",
    "*  Пять побед подряд впервые было одержано в игре  885\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nazZaAbwQGBt"
   },
   "source": [
    "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5ysllZjEQXLa",
    "outputId": "29ec2e79-a0d5-4fcb-a551-6209d40dd7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Победа!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Жадный выбор действий\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "states=[]#Массив для сохранения состояний агента в течение игры\n",
    "t = 0\n",
    "state = env.reset()\n",
    "wn = 0\n",
    "while(t<100):\n",
    "    env.render()\n",
    "    time.sleep(time_delay)\n",
    "    clear_output(wait=True)\n",
    "    action = choose_action_one_game(state)\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    states.append(state)\n",
    "    state = state2\n",
    "    t += 1\n",
    "    if done and reward == 1:\n",
    "        wn=1\n",
    "    if done:\n",
    "        break\n",
    "if wn == 1:\n",
    "    print(\"Победа!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x696NulpReFI"
   },
   "source": [
    "Отобразим маршрут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "UKMCMdpOTcXy",
    "outputId": "bd9a32aa-b615-407f-bb4b-9a2ae654df4f",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:38:02.837292Z",
     "start_time": "2023-10-13T21:38:02.698415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x16b40c970>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "    maze_pic=[]\n",
    "    for i in range(len(maze)):\n",
    "        row = []\n",
    "        for j in range(len(maze[i])):\n",
    "            if maze[i][j] == 'S':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'F':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'H':\n",
    "                row.append(1)\n",
    "            if maze[i][j] == 'G':\n",
    "                row.append(0)\n",
    "        maze_pic.append(row)\n",
    "    maze_pic = np.array(maze_pic)\n",
    "    return maze_pic\n",
    "\n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(random_map)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "rw = np.remainder(states, nrows)\n",
    "cl = np.floor_divide(states, nrows)\n",
    "\n",
    "if wn == 1:\n",
    "    rw = np.append(rw, [nrows-1])\n",
    "    cl = np.append(cl, [ncols-1])\n",
    "\n",
    "path = list(zip(rw, cl))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0], [0], \"gs\", markersize=40)\n",
    "ax1.text(0, 0.2, \"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n",
    "ax1.plot([nrows-1], [ncols-1], \"rs\", markersize=40)\n",
    "ax1.text(nrows-1, ncols-1+0.2, \"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n",
    "ax1.plot(rw, cl, \"bo\")\n",
    "ax1.plot(path[0][0], path[0][1], \"go\", markersize=20)\n",
    "ax1.plot(path[-1][0], path[-1][1], \"ro\", markersize=20)\n",
    "for i in range(len(path)-1):\n",
    "    ax1.plot([path[i][0], path[i+1][0]], [path[i][1], path[i+1][1]], ls='-', color='blue')\n",
    "ax1.set_title('Маршрут последней игры', fontsize=14)\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:38:02.837660Z",
     "start_time": "2023-10-13T21:38:02.823798Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
