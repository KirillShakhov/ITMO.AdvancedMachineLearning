{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9QLe_T6GZUd"
   },
   "source": [
    "# Задание на программирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYlIf2yHv8hz"
   },
   "source": [
    "**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDQzNIZXAoFE"
   },
   "source": [
    "Зададим гиперпараметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "NOMw2ZbOAmOZ",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:36.731823Z",
     "start_time": "2023-10-13T21:43:36.715684Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
    "gamma = 0.9 # Коэффциент дисконтирования гамма\n",
    "random_seed = 2 #Random seed\n",
    "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
    "lr_rate = 0.9 #Коэффициент скорости обучения альфа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQu5IYHX8jId"
   },
   "source": [
    "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "M2G81i4_lOQE",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:37.524874Z",
     "start_time": "2023-10-13T21:43:36.722521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: could not create work tree dir 'gym_0_18_0': No such file or directory\r\n",
      "[Errno 2] No such file or directory: 'gym_0_18_0'\n",
      "/Users/kirill/PycharmProjects/advanced-ml-python-deep-learning/exercise9/gym_0_18_0/gym_0_18_0/gym_0_18_0\n",
      "The folder you are executing pip from can no longer be found.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/pip/__main__.py\", line 8, in <module>\r\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/pip/__main__.py\", line 8, in <module>\r\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Установим нужную версию библиотеки gym\n",
    "!git clone https://github.com/dvolchek/gym_0_18_0.git -q\n",
    "%cd gym_0_18_0\n",
    "!pip install -e. -q\n",
    "%pip install scipy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "awL7CCCwD6C3",
    "outputId": "5b2d42db-dc19-4cef-f753-805b8b6be9c3",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:37.535135Z",
     "start_time": "2023-10-13T21:43:37.531686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваша карта\n",
      "\n",
      "\u001B[41mS\u001B[0mFFFFF\n",
      "FFFFFF\n",
      "FFFFHF\n",
      "HFFFFF\n",
      "FFFFFF\n",
      "FFFFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def generate_random_map(size, p, sd):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "    np.random.seed(sd)\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0,0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r,c) in discovered:\n",
    "                discovered.add((r,c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if (res[r_new][c_new] not in '#H'):\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "#Генерация карты\n",
    "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
    "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
    "print(\"Ваша карта\")\n",
    "env.render() #Выводим карту на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDCexoEU9a_c"
   },
   "source": [
    "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
    "\n",
    "`action = env.action_space.sample()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5TbDqn6G_Pt"
   },
   "source": [
    "# Задача 1\n",
    "Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "CdQBpxaTOK7u",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:37.539802Z",
     "start_time": "2023-10-13T21:43:37.537381Z"
    }
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    action=0\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, done):\n",
    "    # Вычисляем максимальное значение Q для нового состояния state2\n",
    "    # max_q = np.max(Q[state2, :])\n",
    "    \n",
    "    # Обновляем значение Q-функции для текущей пары состояние-действие\n",
    "    # Q[state, action] = (1 - lr_rate) * Q[state, action] + lr_rate * (reward + gamma * max_q)\n",
    "    Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2,:]) - Q[state, action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7COGeyA_Ist3"
   },
   "source": [
    "# Задача 2\n",
    "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0adDl7NvJoQP"
   },
   "source": [
    "Поясним, что возвращает функция ```env.step(action)```\n",
    "\n",
    "```state2``` -- следующее состояние\n",
    "\n",
    "```reward``` -- награда\n",
    "\n",
    "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aq92-dWiOchF",
    "outputId": "91ec4dc4-fb39-4818-ac78-79c9fe6d0ee7",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:39.616860Z",
     "start_time": "2023-10-13T21:43:37.542066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4828.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Inititalization\n",
    "np.random.seed(random_seed)\n",
    "total_games = 10000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "wins_in_a_row = 0\n",
    "total_wins = 0\n",
    "game_of_fifth_win = None\n",
    "\n",
    "# Main cycle\n",
    "for game in tqdm(range(total_games)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "        t += 1\n",
    "        action = choose_action(state)\n",
    "        state2, reward, done, info = env.step(action)\n",
    "        if t == max_steps:\n",
    "            done = True\n",
    "        learn(state, state2, reward, action, done)\n",
    "        state = state2\n",
    "        if done:\n",
    "            if reward > 0:  # if it's a win\n",
    "                total_wins += 1\n",
    "                wins_in_a_row += 1\n",
    "                if wins_in_a_row == 5 and game_of_fifth_win is None:\n",
    "                    game_of_fifth_win = game + 1\n",
    "            else:\n",
    "                wins_in_a_row = 0  # reset the wins in a row counter if the agent didn't win\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFuxsqdRLOS9"
   },
   "source": [
    "Вывод ответов при заданных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "xZbJtFnhLa7w",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:39.619206Z",
     "start_time": "2023-10-13T21:43:39.616760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество побед в серии из 10 000 игр:  9561\n",
      "Пять побед подряд впервые было одержано в игре  81\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество побед в серии из 10 000 игр: \", total_wins)\n",
    "print(\"Пять побед подряд впервые было одержано в игре \", game_of_fifth_win)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSXdSiG2WI71"
   },
   "source": [
    "Должны получиться следующие результаты.\n",
    "\n",
    "\n",
    "*  Количество побед в серии из 10 000 игр:  7914\n",
    "*  Пять побед подряд впервые было одержано в игре  885\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nazZaAbwQGBt"
   },
   "source": [
    "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5ysllZjEQXLa",
    "outputId": "29ec2e79-a0d5-4fcb-a551-6209d40dd7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Победа!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Жадный выбор действий\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "states=[]#Массив для сохранения состояний агента в течение игры\n",
    "t = 0\n",
    "state = env.reset()\n",
    "wn = 0\n",
    "while(t<100):\n",
    "    env.render()\n",
    "    time.sleep(time_delay)\n",
    "    clear_output(wait=True)\n",
    "    action = choose_action_one_game(state)\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    states.append(state)\n",
    "    state = state2\n",
    "    t += 1\n",
    "    if done and reward == 1:\n",
    "        wn=1\n",
    "    if done:\n",
    "        break\n",
    "if wn == 1:\n",
    "    print(\"Победа!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x696NulpReFI"
   },
   "source": [
    "Отобразим маршрут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "UKMCMdpOTcXy",
    "outputId": "bd9a32aa-b615-407f-bb4b-9a2ae654df4f",
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:49.843519Z",
     "start_time": "2023-10-13T21:43:49.717426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x16b4a2ca0>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "    maze_pic=[]\n",
    "    for i in range(len(maze)):\n",
    "        row = []\n",
    "        for j in range(len(maze[i])):\n",
    "            if maze[i][j] == 'S':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'F':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'H':\n",
    "                row.append(1)\n",
    "            if maze[i][j] == 'G':\n",
    "                row.append(0)\n",
    "        maze_pic.append(row)\n",
    "    maze_pic = np.array(maze_pic)\n",
    "    return maze_pic\n",
    "\n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(random_map)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "rw = np.remainder(states, nrows)\n",
    "cl = np.floor_divide(states, nrows)\n",
    "\n",
    "if wn == 1:\n",
    "    rw = np.append(rw, [nrows-1])\n",
    "    cl = np.append(cl, [ncols-1])\n",
    "\n",
    "path = list(zip(rw, cl))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0], [0], \"gs\", markersize=40)\n",
    "ax1.text(0, 0.2, \"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n",
    "ax1.plot([nrows-1], [ncols-1], \"rs\", markersize=40)\n",
    "ax1.text(nrows-1, ncols-1+0.2, \"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n",
    "ax1.plot(rw, cl, \"bo\")\n",
    "ax1.plot(path[0][0], path[0][1], \"go\", markersize=20)\n",
    "ax1.plot(path[-1][0], path[-1][1], \"ro\", markersize=20)\n",
    "for i in range(len(path)-1):\n",
    "    ax1.plot([path[i][0], path[i+1][0]], [path[i][1], path[i+1][1]], ls='-', color='blue')\n",
    "ax1.set_title('Маршрут последней игры', fontsize=14)\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:43:49.863181Z",
     "start_time": "2023-10-13T21:43:49.842274Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
